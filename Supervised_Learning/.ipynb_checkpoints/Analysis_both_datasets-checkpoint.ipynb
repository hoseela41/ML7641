{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "known-advancement",
   "metadata": {},
   "source": [
    "# This jupyter notebook is to implement all five optmized algorithms from two datasets and perform the comparison in terms of accuracy and time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-frederick",
   "metadata": {},
   "source": [
    "## 1. Package installation and function defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "processed-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "import IPython.display as ipd\n",
    "import numpy\n",
    "\n",
    "# sklearn packages\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, average_precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split, cross_val_score, StratifiedKFold, GridSearchCV, validation_curve\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "introductory-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot setting fix\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "matplotlib.rcParams.update({'font.size': 15})\n",
    "\n",
    "# notification of completing the code\n",
    "\n",
    "sound = []\n",
    "def SoundNotification():\n",
    "    global sound\n",
    "    sr = 22050 # sample rate\n",
    "    T = 90    # seconds\n",
    "    t = numpy.linspace(0, T, int(T*sr), endpoint=False) # time variable\n",
    "    x = 0.5*numpy.sin(2*numpy.pi*1000*t)              # pure sine wave at 440 Hz\n",
    "    sound = ipd.Audio(x, rate=sr, autoplay=True) # load a NumPy array\n",
    "\n",
    "    return sound\n",
    "\n",
    "def done():    \n",
    "    sound = SoundNotification()\n",
    "    return sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation test\n",
    "def cvtest(train_X_set, train_y_set, selected_classifier, calculation, average='binary', fold=10, classifier_type = \"DT_classifier\"):\n",
    "    data_size = len(train_X_set)\n",
    "    train_accuracy, validation_accuracy = [], []\n",
    "    num_sample = []\n",
    "    grid_size = 700\n",
    "    starting_size = 100\n",
    "    for i in range(starting_size, data_size, grid_size):\n",
    "        train_X, train_y = train_X_set[:i], train_y_set[: i]\n",
    "        k_fold = StratifiedKFold(n_splits = fold, random_state = None, shuffle = False)\n",
    "        training_list = []\n",
    "        validation_list = []\n",
    "        for train_index, test_index in k_fold.split(train_X, train_y):\n",
    "            # get training and testin x, y data\n",
    "            train_X_part, train_y_part, test_X_part, test_y_part = train_X.iloc[train_index], train_y.iloc[train_index], train_X.iloc[test_index], train_y.iloc[test_index]\n",
    "            # use the classifier for training\n",
    "            if classifier_type == \"adaBoost\" or classifier_type == \"KNN\" or classifier_type == \"SVM\" or classifier_type == \"Neural Network\":\n",
    "                selected_classifier.fit(train_X_part.values, train_y_part.values.ravel()) # needed to be flattened\n",
    "            else:\n",
    "                selected_classifier.fit(train_X_part.values, train_y_part.values)\n",
    "            # get the predicted results from training_y and testing_y\n",
    "            train_y_prediction, test_y_prediction = selected_classifier.predict(train_X_part), selected_classifier.predict(test_X_part)\n",
    "            # do different calculation of average\n",
    "            training_list.append(calculation(train_y_part.values, train_y_prediction, average=average))\n",
    "            validation_list.append(calculation(test_y_part.values, test_y_prediction, average=average))\n",
    "\n",
    "        train_accuracy.append(np.mean(training_list))\n",
    "        validation_accuracy.append(np.mean(validation_list))\n",
    "        num_sample.append(i)\n",
    "        \n",
    "    return train_accuracy, validation_accuracy, num_sample\n",
    "\n",
    "# plot the learning curve\n",
    "def plot_lc(cv_study, title):\n",
    "    num_sample = cv_study[2]\n",
    "    new_x = [100 * x / num_sample[-1] for x in num_sample]\n",
    "    plt.plot(new_x, cv_study[0], \"r-x\", linewidth=2.5, label=\"training\")\n",
    "    plt.plot(new_x, cv_study[1], \"b-x\", linewidth=2.5, label=\"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.xlabel('Percentage of training samples (%)')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
    "    plt.savefig(\"phishing_\" + title + \".png\")\n",
    "\n",
    "        \n",
    "def plot_optimization(training, testing, parameter, title, variable):\n",
    "    plt.plot(parameter, training, \"r-x\", linewidth = 2.5, label = \"training\")\n",
    "    plt.plot(parameter, testing, \"b-x\", linewidth = 2.5, label = \"validation\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel(variable)\n",
    "    plt.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
    "    plt.savefig(\"phising_\" + title + \".png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-suspect",
   "metadata": {},
   "source": [
    "## 2. file loading and data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-injury",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =================== diabetes =========================\n",
    "# load file\n",
    "diabetes_dataset = pd.read_csv(\"diabetes.csv\")\n",
    "\n",
    "# check if there's any NA for both files, if yes, then drop\n",
    "diabetes_dataset.isnull().any().any()\n",
    "diabetes_dataset.dropna()\n",
    "\n",
    "# set the random seed as 56\n",
    "np.random.seed(56)\n",
    "print(\"diabetes information:\", diabetes_dataset.info())\n",
    "\n",
    "# remove unnecessary column\n",
    "cleaned_diabetes_data = diabetes_dataset.drop(columns = [\"PatientID\"], inplace = False) # patientID is meaningless\n",
    "\n",
    "# normalized the data\n",
    "normalized = preprocessing.MinMaxScaler().fit_transform(cleaned_diabetes_data.values)\n",
    "cleaned_diabetes_data = pd.DataFrame(normalized, columns = cleaned_diabetes_data.columns)\n",
    "# print(cleaned_diabetes_data.shape)\n",
    "cleaned_diabetes_data.head(n = 10)\n",
    "\n",
    "# =================== phishing =========================\n",
    "# load file\n",
    "phishing_dataset = pd.read_csv(\"phishing.csv\")\n",
    "\n",
    "# check if there's any NA for both files, if yes, then drop\n",
    "phishing_dataset.isnull().any().any()\n",
    "phishing_dataset.dropna()\n",
    "\n",
    "# set the random seed as 56\n",
    "np.random.seed(56)\n",
    "print(\"phishing information:\", phishing_dataset.info())\n",
    "\n",
    "# remove unnecessary column\n",
    "cleaned_phishing_data = phishing_dataset.drop(columns = [\"Index\"], inplace = False) # patientID is meaningless\n",
    "\n",
    "# normalized the data\n",
    "normalized = preprocessing.MinMaxScaler().fit_transform(cleaned_phishing_data.values)\n",
    "cleaned_phishing_data = pd.DataFrame(normalized, columns = cleaned_phishing_data.columns)\n",
    "cleaned_phishing_data.head(n = 10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:CS6476] *",
   "language": "python",
   "name": "conda-env-CS6476-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
